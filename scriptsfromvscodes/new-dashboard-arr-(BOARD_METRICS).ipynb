{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main subscription data\n",
    "df_main = pd.read_excel('/Users/emirkabasoglu/Desktop/Eloomi/VS Codes/Jupyter Notebook Scripts/Snowflake Scripts/Board_Metrics_Input_File.xlsx')\n",
    "# df_main = pd.read_excel('/Users/jesperfriislarnaes/Library/CloudStorage/OneDrive-eloomi/Scripts/New_Dashboard/test-data-a.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dates - report date is the month after the one being reported on\n",
    "report_date = date(2023,10,1)\n",
    "ltm_period_start = report_date + relativedelta(months=-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO CALCULATE ARR\n",
    "def arr_ltm_calculations(df, name):\n",
    "    # Function to get ARR main grid\n",
    "    def ltm_arr(df, ltm_period_start, ltm_period_end):\n",
    "        while ltm_period_start < ltm_period_end:\n",
    "            revenue_period = ltm_period_start + relativedelta(months=+1, days=-1)\n",
    "            mask_active = (df['start'].dt.date <= revenue_period) & (df['end'].dt.date >= revenue_period)\n",
    "            if df.empty:\n",
    "                df[f'{revenue_period}'] = np.nan\n",
    "            else:\n",
    "                df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
    "            ltm_period_start = ltm_period_start + relativedelta(months=+1)\n",
    "        return df\n",
    "\n",
    "    # Run function using dataframe as input and current_end_of_month to define the ltm period range\n",
    "    df_ltm_arr = ltm_arr(df, ltm_period_start, report_date)\n",
    "\n",
    "    # Group by ids to get grid on account level\n",
    "    revenue_period_cols = list(df_ltm_arr.iloc[:,12:])\n",
    "    df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
    "    df_ltm_arr_agg.to_excel(f'{name}-ltm-arr-per-account.xlsx')\n",
    "\n",
    "    # Set up dataframe for arr ending\n",
    "    df_arr_ending = df_ltm_arr_agg.agg(['sum']).rename(index={'sum': f'{name}_arr_ending'})\n",
    "\n",
    "    # Set up dataframe for arr churn \n",
    "    df_arr_churn = df_ltm_arr_agg.diff(axis=1)[df_ltm_arr_agg.eq(0)].agg(['sum']).rename(index={'sum': f'{name}_arr_churn'})\n",
    "\n",
    "    # Set up dataframe for new logo arr\n",
    "    df_arr_new_logo = df_ltm_arr_agg.diff(axis=1)[df_ltm_arr_agg.eq(0).shift(axis=1)].agg(['sum']).rename(index={'sum': f'{name}_arr_new_logo'})\n",
    "\n",
    "    # Set up dataframe for upsell arr\n",
    "    mask_arr_upsell = df_ltm_arr_agg[df_ltm_arr_agg.gt(0)].diff(axis=1).fillna(0).gt(0)\n",
    "    df_arr_upsell = df_ltm_arr_agg.diff(axis=1)[mask_arr_upsell].agg(['sum']).rename(index={'sum': f'{name}_arr_upsell'})\n",
    "\n",
    "    # Set up dataframe for downsell arr\n",
    "    mask_arr_downsell = df_ltm_arr_agg[df_ltm_arr_agg.gt(0)].diff(axis=1).fillna(0).lt(0)\n",
    "    df_arr_downsell = df_ltm_arr_agg.diff(axis=1)[mask_arr_downsell].agg(['sum']).rename(index={'sum': f'{name}_arr_downsell'})\n",
    "\n",
    "    # Set up dataframe for arr ending logo count\n",
    "    df_arr_ending_logo_count = df_ltm_arr_agg.replace(0,np.nan).count().to_frame(name=f'{name}_arr_ending_logo_count').transpose()\n",
    "\n",
    "    # Set up dataframe for arr churn logo count\n",
    "    df_arr_churn_logo_count = df_ltm_arr_agg.diff(axis=1)[df_ltm_arr_agg.eq(0)].replace(0,np.nan).count().to_frame(name=f'{name}_arr_churn_logo_count').transpose()\n",
    "\n",
    "    # Set up dataframe for arr new logo count\n",
    "    df_arr_new_logo_count = df_ltm_arr_agg.diff(axis=1)[df_ltm_arr_agg.eq(0).shift(axis=1)].replace(0,np.nan).count().to_frame(name=f'{name}_arr_new_logo_count').transpose()\n",
    "\n",
    "    # Set up dataframe for arr upsell logo count\n",
    "    mask_arr_upsell = df_ltm_arr_agg[df_ltm_arr_agg.gt(0)].diff(axis=1).fillna(0).gt(0)\n",
    "    df_arr_upsell_logo_count = df_ltm_arr_agg.diff(axis=1)[mask_arr_upsell].replace(0,np.nan).count().to_frame(name=f'{name}_arr_upsell_logo_count').transpose()\n",
    "\n",
    "    # Set up dataframe for downsell arr logo count\n",
    "    mask_arr_downsell = df_ltm_arr_agg[df_ltm_arr_agg.gt(0)].diff(axis=1).fillna(0).lt(0)\n",
    "    df_arr_downsell_logo_count = df_ltm_arr_agg.diff(axis=1)[mask_arr_downsell].replace(0,np.nan).count().to_frame(name=f'{name}_arr_downsell_logo_count').transpose()\n",
    "\n",
    "    # Set up concatenated dataframe\n",
    "    arr_dfs = pd.concat([df_arr_new_logo, df_arr_churn, df_arr_upsell, df_arr_downsell, df_arr_ending, df_arr_new_logo_count, df_arr_churn_logo_count, df_arr_upsell_logo_count, df_arr_downsell_logo_count, df_arr_ending_logo_count], axis=0)\n",
    "    return arr_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "At least one sheet must be visible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m size:\n\u001b[0;32m----> 7\u001b[0m     df \u001b[39m=\u001b[39m arr_ltm_calculations(df_main[(df_main[\u001b[39m'\u001b[39m\u001b[39mregion\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m r) \u001b[39m&\u001b[39m (df_main[\u001b[39m'\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m s)], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m_arr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     df\u001b[39m.\u001b[39mto_excel(writer, sheet_name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m_arr\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'size'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m product_type \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpeople\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minfinite\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m region:\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mwith\u001b[39;00m pd\u001b[39m.\u001b[39mExcelWriter(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mreport_date\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m-arr.xlsx\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m writer:\n\u001b[1;32m      6\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m size:\n\u001b[1;32m      7\u001b[0m             df \u001b[39m=\u001b[39m arr_ltm_calculations(df_main[(df_main[\u001b[39m'\u001b[39m\u001b[39mregion\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m r) \u001b[39m&\u001b[39m (df_main[\u001b[39m'\u001b[39m\u001b[39msize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m s)], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mr\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m_arr\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_base.py:1476\u001b[0m, in \u001b[0;36mExcelWriter.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_value, traceback) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1476\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_base.py:1480\u001b[0m, in \u001b[0;36mExcelWriter.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclose\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1479\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1480\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n\u001b[1;32m   1481\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:109\u001b[0m, in \u001b[0;36mOpenpyxlWriter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_save\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39m    Save workbook to disk.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbook\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handles\u001b[39m.\u001b[39;49mhandle)\n\u001b[1;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles\u001b[39m.\u001b[39mhandle, mmap\u001b[39m.\u001b[39mmmap):\n\u001b[1;32m    111\u001b[0m         \u001b[39m# truncate file to the written content\u001b[39;00m\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handles\u001b[39m.\u001b[39mhandle\u001b[39m.\u001b[39mtruncate()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/workbook/workbook.py:407\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_only \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworksheets:\n\u001b[1;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_sheet()\n\u001b[0;32m--> 407\u001b[0m save_workbook(\u001b[39mself\u001b[39;49m, filename)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/writer/excel.py:293\u001b[0m, in \u001b[0;36msave_workbook\u001b[0;34m(workbook, filename)\u001b[0m\n\u001b[1;32m    291\u001b[0m archive \u001b[39m=\u001b[39m ZipFile(filename, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, ZIP_DEFLATED, allowZip64\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    292\u001b[0m writer \u001b[39m=\u001b[39m ExcelWriter(workbook, archive)\n\u001b[0;32m--> 293\u001b[0m writer\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m    294\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/writer/excel.py:275\u001b[0m, in \u001b[0;36mExcelWriter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Write data into the archive.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_data()\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_archive\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/writer/excel.py:89\u001b[0m, in \u001b[0;36mExcelWriter.write_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m writer \u001b[39m=\u001b[39m WorkbookWriter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkbook)\n\u001b[1;32m     88\u001b[0m archive\u001b[39m.\u001b[39mwritestr(ARC_ROOT_RELS, writer\u001b[39m.\u001b[39mwrite_root_rels())\n\u001b[0;32m---> 89\u001b[0m archive\u001b[39m.\u001b[39mwritestr(ARC_WORKBOOK, writer\u001b[39m.\u001b[39;49mwrite())\n\u001b[1;32m     90\u001b[0m archive\u001b[39m.\u001b[39mwritestr(ARC_WORKBOOK_RELS, writer\u001b[39m.\u001b[39mwrite_rels())\n\u001b[1;32m     92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_vba()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/workbook/_writer.py:148\u001b[0m, in \u001b[0;36mWorkbookWriter.write\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_names()\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_pivots()\n\u001b[0;32m--> 148\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_views()\n\u001b[1;32m    149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite_refs()\n\u001b[1;32m    151\u001b[0m \u001b[39mreturn\u001b[39;00m tostring(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpackage\u001b[39m.\u001b[39mto_tree())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/workbook/_writer.py:135\u001b[0m, in \u001b[0;36mWorkbookWriter.write_views\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_views\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 135\u001b[0m     active \u001b[39m=\u001b[39m get_active_sheet(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwb)\n\u001b[1;32m    136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwb\u001b[39m.\u001b[39mviews:\n\u001b[1;32m    137\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwb\u001b[39m.\u001b[39mviews[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mactiveTab \u001b[39m=\u001b[39m active\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/workbook/_writer.py:33\u001b[0m, in \u001b[0;36mget_active_sheet\u001b[0;34m(wb)\u001b[0m\n\u001b[1;32m     31\u001b[0m visible_sheets \u001b[39m=\u001b[39m [idx \u001b[39mfor\u001b[39;00m idx, sheet \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(wb\u001b[39m.\u001b[39m_sheets) \u001b[39mif\u001b[39;00m sheet\u001b[39m.\u001b[39msheet_state \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisible\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m visible_sheets:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one sheet must be visible\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m idx \u001b[39m=\u001b[39m wb\u001b[39m.\u001b[39m_active_sheet_index\n\u001b[1;32m     36\u001b[0m sheet \u001b[39m=\u001b[39m wb\u001b[39m.\u001b[39mactive\n",
      "\u001b[0;31mIndexError\u001b[0m: At least one sheet must be visible"
     ]
    }
   ],
   "source": [
    "region = ['norben','dach', 'uk', 'us', 'row']\n",
    "size = ['smb','mm','ent']\n",
    "product_type = ['people', 'infinite']\n",
    "for r in region:\n",
    "    with pd.ExcelWriter(f\"{report_date}-{r}-arr.xlsx\") as writer:\n",
    "        for s in size:\n",
    "            df = arr_ltm_calculations(df_main[(df_main['region'] == r) & (df_main['size'] == s)], f'{r}_{s}_arr')\n",
    "            df.to_excel(writer, sheet_name=f\"{r}_{s}_arr\")\n",
    "        for t in product_type:\n",
    "            df = arr_ltm_calculations(df_main[(df_main['region'] == r) & (df_main['type'] == t)], f'{r}_{t}_arr')\n",
    "            df.to_excel(writer, sheet_name=f\"{r}_{t}_arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# ALL GEOS\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Size split total arr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# total arr\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_total_filter \u001b[39m=\u001b[39m df_main\n\u001b[0;32m----> 5\u001b[0m df_total \u001b[39m=\u001b[39m arr_ltm_calculations(df_total_filter, \u001b[39m'\u001b[39;49m\u001b[39mall_geos_total\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# smb total arr\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df_smb_total_filter \u001b[39m=\u001b[39m df_main[df_main[\u001b[39m'\u001b[39m\u001b[39msize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msmb\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[21], line 20\u001b[0m, in \u001b[0;36marr_ltm_calculations\u001b[0;34m(df, name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Group by ids to get grid on account level\u001b[39;00m\n\u001b[1;32m     19\u001b[0m revenue_period_cols \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_ltm_arr\u001b[39m.\u001b[39miloc[:,\u001b[39m12\u001b[39m:])\n\u001b[0;32m---> 20\u001b[0m df_ltm_arr_agg \u001b[39m=\u001b[39m df_ltm_arr\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m)[revenue_period_cols]\u001b[39m.\u001b[39msum()\n\u001b[1;32m     21\u001b[0m df_ltm_arr_agg\u001b[39m.\u001b[39mto_excel(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m-ltm-arr-per-account.xlsx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Set up dataframe for arr ending\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8403\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8404\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8405\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8406\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8407\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8408\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8409\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8410\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[1;32m   8411\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8412\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8413\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    966\u001b[0m         obj,\n\u001b[1;32m    967\u001b[0m         keys,\n\u001b[1;32m    968\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    969\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    970\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    971\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    972\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    973\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    976\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# ALL GEOS\n",
    "# Size split total arr\n",
    "# total arr\n",
    "df_total_filter = df_main\n",
    "df_total = arr_ltm_calculations(df_total_filter, 'all_geos_total')\n",
    "\n",
    "# smb total arr\n",
    "df_smb_total_filter = df_main[df_main['size'] == 'smb']\n",
    "df_smb_total = arr_ltm_calculations(df_smb_total_filter, 'all_geos_smb')\n",
    "\n",
    "# mm total arr\n",
    "df_mm_total_filter = df_main[df_main['size'] == 'mm']\n",
    "df_mm_total = arr_ltm_calculations(df_mm_total_filter, 'all_geos_mm')\n",
    "\n",
    "# ent total arr\n",
    "df_ent_total_filter = df_main[df_main['size'] == 'ent']\n",
    "df_ent_total = arr_ltm_calculations(df_ent_total_filter, 'all_geos_ent')\n",
    "\n",
    "# Product split total arr\n",
    "# Software total\n",
    "df_software_total_filter = df_main[df_main['product'] == 'software']\n",
    "df_software_total = arr_ltm_calculations(df_software_total_filter, 'all_geos_software')\n",
    "\n",
    "# Content total\n",
    "df_content_total_filter = df_main[df_main['product'] == 'content']\n",
    "df_content_total = arr_ltm_calculations(df_content_total_filter, 'all_geos_content')\n",
    "\n",
    "# Type split total arr\n",
    "# People total\n",
    "df_people_total_filter = df_main[df_main['type'] == 'people']\n",
    "df_people_total = arr_ltm_calculations(df_people_total_filter, 'all_geos_people')\n",
    "\n",
    "# Infinite total\n",
    "df_infinite_total_filter = df_main[df_main['type'] == 'infinite']\n",
    "df_infinite_total = arr_ltm_calculations(df_infinite_total_filter, 'all_geos_infinite')\n",
    "\n",
    "# Create output excel file for geo \n",
    "# # create a excel writer object\n",
    "with pd.ExcelWriter(f\"{report_date}-all-geos-arr.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    df_total.to_excel(writer, sheet_name=\"all-geos-total-arr\")\n",
    "    df_smb_total.to_excel(writer, sheet_name=\"all-geos-smb-arr\")\n",
    "    df_mm_total.to_excel(writer, sheet_name=\"all-geos-mm-arr\")\n",
    "    df_ent_total.to_excel(writer, sheet_name=\"all-geos-ent-arr\")\n",
    "    df_software_total.to_excel(writer, sheet_name=\"all-geos-software-arr\")\n",
    "    df_content_total.to_excel(writer, sheet_name=\"all-geos-content-arr\")\n",
    "    df_people_total.to_excel(writer, sheet_name=\"all-geos-people-arr\")\n",
    "    df_infinite_total.to_excel(writer, sheet_name=\"all-geos-infinite-arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n"
     ]
    }
   ],
   "source": [
    "# # NORBEN\n",
    "# # Total and size split arr\n",
    "# # total arr\n",
    "df_norben_total_filter = df_main[df_main['region'] == 'norben']\n",
    "df_norben_total = arr_ltm_calculations(df_norben_total_filter, 'norben_total')\n",
    "\n",
    "# # smb total arr\n",
    "df_norben_smb_filter = df_main[(df_main['region'] == 'norben') & (df_main['size'] == 'smb')]\n",
    "df_norben_smb = arr_ltm_calculations(df_norben_smb_filter, 'norben_smb')\n",
    "\n",
    "# # mm total arr\n",
    "df_norben_mm_filter = df_main[(df_main['region'] == 'norben') & (df_main['size'] == 'mm')]\n",
    "df_norben_mm = arr_ltm_calculations(df_norben_mm_filter, 'norben_mm')\n",
    "\n",
    "# # ent total arr\n",
    "df_norben_ent_filter = df_main[(df_main['region'] == 'norben') & (df_main['size'] == 'ent')]\n",
    "df_norben_ent = arr_ltm_calculations(df_norben_ent_filter, 'norben_ent')\n",
    "\n",
    "# Type split total arr\n",
    "# People total\n",
    "df_norben_people_filter = df_main[(df_main['region'] == 'norben') & (df_main['type'] == 'people')]\n",
    "df_norben_people = arr_ltm_calculations(df_norben_people_filter, 'norben_people')\n",
    "\n",
    "# Infinite total\n",
    "df_norben_infinite_filter = df_main[(df_main['region'] == 'norben') & (df_main['type'] == 'infinite')]\n",
    "df_norben_infinite = arr_ltm_calculations(df_norben_infinite_filter, 'norben_infinite')\n",
    "\n",
    "# Create output excel file for geo\n",
    "\n",
    "# create a excel writer object\n",
    "with pd.ExcelWriter(f\"{report_date}-norben-arr.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    df_norben_total.to_excel(writer, sheet_name=\"norben-total-arr\")\n",
    "    df_norben_smb.to_excel(writer, sheet_name=\"norben-smb-arr\")\n",
    "    df_norben_mm.to_excel(writer, sheet_name=\"norben-mm-arr\")\n",
    "    df_norben_ent.to_excel(writer, sheet_name=\"norben-ent-arr\")\n",
    "    df_norben_people.to_excel(writer, sheet_name=\"norben-people-arr\")\n",
    "    df_norben_infinite.to_excel(writer, sheet_name=\"norben-infinite-arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n"
     ]
    }
   ],
   "source": [
    "# # DACH\n",
    "# # Total and size split arr\n",
    "# # total arr\n",
    "df_dach_total_filter = df_main[df_main['region'] == 'dach']\n",
    "df_dach_total = arr_ltm_calculations(df_dach_total_filter, 'dach_total')\n",
    "\n",
    "# # smb total arr\n",
    "df_dach_smb_filter = df_main[(df_main['region'] == 'dach') & (df_main['size'] == 'smb')]\n",
    "df_dach_smb = arr_ltm_calculations(df_dach_smb_filter, 'dach_smb')\n",
    "\n",
    "# # mm total arr\n",
    "df_dach_mm_filter = df_main[(df_main['region'] == 'dach') & (df_main['size'] == 'mm')]\n",
    "df_dach_mm = arr_ltm_calculations(df_dach_mm_filter, 'dach_mm')\n",
    "\n",
    "# # ent total arr\n",
    "df_dach_ent_filter = df_main[(df_main['region'] == 'dach') & (df_main['size'] == 'ent')]\n",
    "df_dach_ent = arr_ltm_calculations(df_dach_ent_filter, 'dach_ent')\n",
    "\n",
    "# Type split total arr\n",
    "# People total\n",
    "df_dach_people_filter = df_main[(df_main['region'] == 'dach') & (df_main['type'] == 'people')]\n",
    "df_dach_people = arr_ltm_calculations(df_dach_people_filter, 'dach_people')\n",
    "\n",
    "# Infinite total\n",
    "df_dach_infinite_filter = df_main[(df_main['region'] == 'dach') & (df_main['type'] == 'infinite')]\n",
    "df_dach_infinite = arr_ltm_calculations(df_dach_infinite_filter, 'dach_infinite')\n",
    "\n",
    "# Create output excel file for geo\n",
    "\n",
    "# create a excel writer object\n",
    "with pd.ExcelWriter(f\"{report_date}-dach-arr.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    df_dach_total.to_excel(writer, sheet_name=\"dach-total-arr\")\n",
    "    df_dach_smb.to_excel(writer, sheet_name=\"dach-smb-arr\")\n",
    "    df_dach_mm.to_excel(writer, sheet_name=\"dach-mm-arr\")\n",
    "    df_dach_ent.to_excel(writer, sheet_name=\"dach-ent-arr\")\n",
    "    df_dach_people.to_excel(writer, sheet_name=\"dach-people-arr\")\n",
    "    df_dach_infinite.to_excel(writer, sheet_name=\"dach-infinite-arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n"
     ]
    }
   ],
   "source": [
    "# # UK\n",
    "# # Total and size split arr\n",
    "# # total arr\n",
    "df_uk_total_filter = df_main[df_main['region'] == 'uk']\n",
    "df_uk_total = arr_ltm_calculations(df_uk_total_filter, 'uk_total')\n",
    "\n",
    "# # smb total arr\n",
    "df_uk_smb_filter = df_main[(df_main['region'] == 'uk') & (df_main['size'] == 'smb')]\n",
    "df_uk_smb = arr_ltm_calculations(df_uk_smb_filter, 'uk_smb')\n",
    "\n",
    "# # mm total arr\n",
    "df_uk_mm_filter = df_main[(df_main['region'] == 'uk') & (df_main['size'] == 'mm')]\n",
    "df_uk_mm = arr_ltm_calculations(df_uk_mm_filter, 'uk_mm')\n",
    "\n",
    "# # ent total arr\n",
    "df_uk_ent_filter = df_main[(df_main['region'] == 'uk') & (df_main['size'] == 'ent')]\n",
    "df_uk_ent = arr_ltm_calculations(df_uk_ent_filter, 'uk_ent')\n",
    "\n",
    "# Type split total arr\n",
    "# People total\n",
    "df_uk_people_filter = df_main[(df_main['region'] == 'uk') & (df_main['type'] == 'people')]\n",
    "df_uk_people = arr_ltm_calculations(df_uk_people_filter, 'uk_people')\n",
    "\n",
    "# Infinite total\n",
    "df_uk_infinite_filter = df_main[(df_main['region'] == 'uk') & (df_main['type'] == 'infinite')]\n",
    "df_uk_infinite = arr_ltm_calculations(df_uk_infinite_filter, 'uk_infinite')\n",
    "\n",
    "# Create output excel file for geo\n",
    "\n",
    "# create a excel writer object\n",
    "with pd.ExcelWriter(f\"{report_date}-uk-arr.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    df_uk_total.to_excel(writer, sheet_name=\"uk-total-arr\")\n",
    "    df_uk_smb.to_excel(writer, sheet_name=\"uk-smb-arr\")\n",
    "    df_uk_mm.to_excel(writer, sheet_name=\"uk-mm-arr\")\n",
    "    df_uk_ent.to_excel(writer, sheet_name=\"uk-ent-arr\")\n",
    "    df_uk_people.to_excel(writer, sheet_name=\"uk-people-arr\")\n",
    "    df_uk_infinite.to_excel(writer, sheet_name=\"uk-infinite-arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n"
     ]
    }
   ],
   "source": [
    "# # US\n",
    "# # Total and size split arr\n",
    "# # total arr\n",
    "df_us_total_filter = df_main[df_main['region'] == 'us']\n",
    "df_us_total = arr_ltm_calculations(df_us_total_filter, 'us_total')\n",
    "\n",
    "# # smb total arr\n",
    "df_us_smb_filter = df_main[(df_main['region'] == 'us') & (df_main['size'] == 'smb')]\n",
    "df_us_smb = arr_ltm_calculations(df_us_smb_filter, 'us_smb')\n",
    "\n",
    "# # mm total arr\n",
    "df_us_mm_filter = df_main[(df_main['region'] == 'us') & (df_main['size'] == 'mm')]\n",
    "df_us_mm = arr_ltm_calculations(df_us_mm_filter, 'us_mm')\n",
    "\n",
    "# # ent total arr\n",
    "df_us_ent_filter = df_main[(df_main['region'] == 'us') & (df_main['size'] == 'ent')]\n",
    "df_us_ent = arr_ltm_calculations(df_us_ent_filter, 'us_ent')\n",
    "\n",
    "# Type split total arr\n",
    "# People total\n",
    "df_us_people_filter = df_main[(df_main['region'] == 'us') & (df_main['type'] == 'people')]\n",
    "df_us_people = arr_ltm_calculations(df_us_people_filter, 'us_people')\n",
    "\n",
    "# Infinite total\n",
    "df_us_infinite_filter = df_main[(df_main['region'] == 'us') & (df_main['type'] == 'infinite')]\n",
    "df_us_infinite = arr_ltm_calculations(df_us_infinite_filter, 'us_infinite')\n",
    "\n",
    "# Create output excel file for geo\n",
    "\n",
    "# create a excel writer object\n",
    "with pd.ExcelWriter(f\"{report_date}-us-arr.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    df_us_total.to_excel(writer, sheet_name=\"us-total-arr\")\n",
    "    df_us_smb.to_excel(writer, sheet_name=\"us-smb-arr\")\n",
    "    df_us_mm.to_excel(writer, sheet_name=\"us-mm-arr\")\n",
    "    df_us_ent.to_excel(writer, sheet_name=\"us-ent-arr\")\n",
    "    df_us_people.to_excel(writer, sheet_name=\"us-people-arr\")\n",
    "    df_us_infinite.to_excel(writer, sheet_name=\"us-infinite-arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f'{revenue_period}'] = df.loc[mask_active]['value']\n",
      "/var/folders/84/np97p6s9023f4v7_n4n1nqk40000gp/T/ipykernel_16528/1886470345.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_ltm_arr_agg = df_ltm_arr.groupby('id')[revenue_period_cols].sum()\n"
     ]
    }
   ],
   "source": [
    "# # ROW\n",
    "# # Total and size split arr\n",
    "# # total arr\n",
    "df_row_total_filter = df_main[df_main['region'] == 'row']\n",
    "df_row_total = arr_ltm_calculations(df_row_total_filter, 'row_total')\n",
    "\n",
    "# # smb total arr\n",
    "df_row_smb_filter = df_main[(df_main['region'] == 'row') & (df_main['size'] == 'smb')]\n",
    "df_row_smb = arr_ltm_calculations(df_row_smb_filter, 'row_smb')\n",
    "\n",
    "# # mm total arr\n",
    "df_row_mm_filter = df_main[(df_main['region'] == 'row') & (df_main['size'] == 'mm')]\n",
    "df_row_mm = arr_ltm_calculations(df_row_mm_filter, 'row_mm')\n",
    "\n",
    "# # ent total arr\n",
    "df_row_ent_filter = df_main[(df_main['region'] == 'row') & (df_main['size'] == 'ent')]\n",
    "df_row_ent = arr_ltm_calculations(df_row_ent_filter, 'row_ent')\n",
    "\n",
    "# Type split total arr\n",
    "# People total\n",
    "df_row_people_filter = df_main[(df_main['region'] == 'row') & (df_main['type'] == 'people')]\n",
    "df_row_people = arr_ltm_calculations(df_row_people_filter, 'row_people')\n",
    "\n",
    "# Infinite total\n",
    "df_row_infinite_filter = df_main[(df_main['region'] == 'row') & (df_main['type'] == 'infinite')]\n",
    "df_row_infinite = arr_ltm_calculations(df_row_infinite_filter, 'row_infinite')\n",
    "\n",
    "# Create output excel file for geo\n",
    "\n",
    "# create a excel writer object\n",
    "with pd.ExcelWriter(f\"{report_date}-row-arr.xlsx\") as writer:\n",
    "   \n",
    "    # use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    df_row_total.to_excel(writer, sheet_name=\"row-total-arr\")\n",
    "    df_row_smb.to_excel(writer, sheet_name=\"row-smb-arr\")\n",
    "    df_row_mm.to_excel(writer, sheet_name=\"row-mm-arr\")\n",
    "    df_row_ent.to_excel(writer, sheet_name=\"row-ent-arr\")\n",
    "    df_row_people.to_excel(writer, sheet_name=\"row-people-arr\")\n",
    "    df_row_infinite.to_excel(writer, sheet_name=\"row-infinite-arr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "####    END         ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38aef752a079a85de1739380fb1638eeeade851c41e3775971b8ec62af2e1c1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
